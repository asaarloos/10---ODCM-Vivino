{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Team Project ODCM - Team 10\n",
        "\n",
        "## Project \n",
        "In this document is the code written to scrape the data from Vivino. The extracted data could be used to analyse the influence of the price of wine on consumer ratings. The Vivino website offers over millions of different wines, it is impossible to scrape all of them. Therefore, we made created a sample of wines we are going to scrape. This sample consists of all wines originated in Spain and that is deliverable to the Netherlands. As of 05-10-2024 This leaves a sample of 8,079 wines (this number could change over time). Of these wines, the following data will be extracted:\n",
        "- **Hyperlink**: The hyperlink of each wine, which includes the unique id of each wine. The unique wine id will later be isolated when cleaning the data.\n",
        "- **Brand**: The brand that produces the wine.\n",
        "- **Wine**: The name of the specific wine.\n",
        "- **Rating**: The star rating of the specific wine (0-5).\n",
        "- **Price**: The price of the specific wine. When the wine is on discount, the original price will be taken, not the discounted price.\n",
        "- **Timestamp**: The timestamp at which the data is extracted. This is useful if the dataset will be used in future analysis, so the date and time of extraction can always be found.\n",
        "\n",
        "*Important note: Since the Vivino website offerse some wines multiple times, later the duplicate rows will be deleted, which leaves a sample of 7,585 wines*\n",
        "\n",
        "### Code\n",
        "The code will run individually for each type of wine: red, white, rose, sparkling, dessert and fortified. After the code of each type is run, a dataset will be created containing all wines of that type. Later, when cleaning the data, each dataset will get identified by adding an extra column with the type. Then, all datasets will be merged into one dataset containing all 8,057 wines. This dataset will be further cleaned and after removing duplicate wines, it will producte a final dataset with 7,585 wines.\n",
        "\n",
        "We created a makefile to automate this process. When running the makefile (located in the GitHub repository), it will first run this webscraping code, creating seperate datasets per type of wine. Because there is no need anymore for the seperate datasets (since they are all merged together), the makefile will also deleted the seperate datasets created by the webscraper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install the packages & librabies \n",
        "\n",
        "To extract the date, we make use of Beautiful Soup and Selenium. In order to run the code, first install and import the packages below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KqSSIap269zb",
        "outputId": "2e966433-ea96-4460-e83b-c65fc6cb8bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in c:\\users\\31637\\anaconda3\\lib\\site-packages (4.25.0)\n",
            "Requirement already satisfied: trio~=0.17 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from selenium) (0.26.2)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
            "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: idna in c:\\users\\31637\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
            "Requirement already satisfied: outcome in c:\\users\\31637\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sortedcontainers in c:\\users\\31637\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: exceptiongroup in c:\\users\\31637\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
            "Requirement already satisfied: pycparser in c:\\users\\31637\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Requirement already satisfied: webdriver_manager in c:\\users\\31637\\anaconda3\\lib\\site-packages (4.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\31637\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.26.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\31637\\anaconda3\\lib\\site-packages (from webdriver_manager) (24.1)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\31637\\anaconda3\\lib\\site-packages (from webdriver_manager) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (1.26.7)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\31637\\anaconda3\\lib\\site-packages (4.10.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\31637\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n"
          ]
        }
      ],
      "source": [
        "#installing packages\n",
        "!pip3 install selenium\n",
        "!pip3 install webdriver_manager\n",
        "!pip3 install beautifulsoup4\n",
        "\n",
        "#libraries\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Red Wines \n",
        "\n",
        "In the cell below we are collecting the data of the red wines. To be safe that the code doesn't break, we seperate the wines we want to extract into 4 seperate urls. These urls are then, one by one, fed into the code using a for loop. After scraping, the data will be appended to a csv file names 'red_wine.csv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cookies accepted.\n"
          ]
        },
        {
          "ename": "NoSuchWindowException",
          "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=129.0.6668.70)\nStacktrace:\n\tGetHandleVerifier [0x00717143+25587]\n\t(No symbol) [0x006AA2E4]\n\t(No symbol) [0x005A2113]\n\t(No symbol) [0x0057E23B]\n\t(No symbol) [0x0061179F]\n\t(No symbol) [0x00624CB9]\n\t(No symbol) [0x0060A936]\n\t(No symbol) [0x005DBA73]\n\t(No symbol) [0x005DC4CD]\n\tGetHandleVerifier [0x009F4C63+3030803]\n\tGetHandleVerifier [0x00A46B99+3366473]\n\tGetHandleVerifier [0x007A95F2+624802]\n\tGetHandleVerifier [0x007B0E6C+655644]\n\t(No symbol) [0x006B2C9D]\n\t(No symbol) [0x006AFD68]\n\t(No symbol) [0x006AFF05]\n\t(No symbol) [0x006A2336]\n\tBaseThreadInitThunk [0x75067BA9+25]\n\tRtlInitializeExceptionChain [0x7701C0CB+107]\n\tRtlClearBits [0x7701C04F+191]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22256/2955490853.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Calculate new scroll height and compare with the last scroll height\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mnew_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"return document.body.scrollHeight\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnew_height\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlast_height\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                   \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscroll_pause_time\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Wait for the potentially new content to load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\31637\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW3C_EXECUTE_SCRIPT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"script\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"args\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconverted_args\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_async_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\31637\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\31637\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=129.0.6668.70)\nStacktrace:\n\tGetHandleVerifier [0x00717143+25587]\n\t(No symbol) [0x006AA2E4]\n\t(No symbol) [0x005A2113]\n\t(No symbol) [0x0057E23B]\n\t(No symbol) [0x0061179F]\n\t(No symbol) [0x00624CB9]\n\t(No symbol) [0x0060A936]\n\t(No symbol) [0x005DBA73]\n\t(No symbol) [0x005DC4CD]\n\tGetHandleVerifier [0x009F4C63+3030803]\n\tGetHandleVerifier [0x00A46B99+3366473]\n\tGetHandleVerifier [0x007A95F2+624802]\n\tGetHandleVerifier [0x007B0E6C+655644]\n\t(No symbol) [0x006B2C9D]\n\t(No symbol) [0x006AFD68]\n\t(No symbol) [0x006AFF05]\n\t(No symbol) [0x006A2336]\n\tBaseThreadInitThunk [0x75067BA9+25]\n\tRtlInitializeExceptionChain [0x7701C0CB+107]\n\tRtlClearBits [0x7701C04F+191]\n"
          ]
        }
      ],
      "source": [
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service)\n",
        "\n",
        "urls = ('https://www.vivino.com/explore?e=eJzLLbI1VMvNzLM1UMtNrLA1NFBLrrT181FLtnUNDVIrAEqmp9mWJRZlppYk5qjlF6XYpqQWJ6vlJ1XaFhRlJqeqlZdExwJVJVcWA-nUYjUwCQC3hRy5', # 0-10 euro\n",
        "      'https://www.vivino.com/explore?e=eJzLLbI1VMvNzLM1NFDLTaywNTJQS6609fNRS7Z1DQ1SKwDKpqfZliUWZaaWJOao5Rel2KakFier5SdV2hYUZSanqpWXRMcCVSVXFgPp1GI1MAkAya8c6w%3D%3D', # 10-20 euro\n",
        "      'https://www.vivino.com/explore?e=eJzLLbI1VMvNzLM1MlDLTaywNTFQS6609fNRS7Z1DQ1SKwDKpqfZliUWZaaWJOao5Rel2KakFier5SdV2hYUZSanqpWXRMcCVSVXFgPp1GI1MAkAyosc7g%3D%3D', # 20-40 euro\n",
        "      'https://www.vivino.com/explore?e=eJzLLbI1VMvNzLM1MVDLTaywNTUwUEuutPXzUUu2dQ0NUisASqen2ZYlFmWmliTmqOUXpdimpBYnq-UnVdoWFGUmp6qVl0THAlUlVxYD6dRiNTAJAN31HSE%3D') # 40-500 euro\n",
        "\n",
        "# Open a csv file to store the data in\n",
        "with open('red_wine.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "      writer = csv.writer(file)\n",
        "\n",
        "      # Write the header row\n",
        "      writer.writerow(['hyperlink','Brand', 'Wine', 'Rating', 'Reviews', 'Price','Timestamp'])\n",
        "\n",
        "for url in urls:\n",
        "      driver.get(url)\n",
        "      driver.maximize_window()\n",
        "\n",
        "      # Optional: Adding some wait time for the page to fully load if needed\n",
        "      driver.implicitly_wait(20)\n",
        "\n",
        "      # Create a function to click away the cookies\n",
        "      try:\n",
        "            accept_cookies_button = driver.find_element(By.ID,\"didomi-notice-agree-button\")\n",
        "            accept_cookies_button.click()\n",
        "            print(\"Cookies accepted.\")\n",
        "      except Exception as e:\n",
        "            print(\"Cookie acceptance button not found or could not be clicked:\")\n",
        "\n",
        "      # Infinite scroll to load more content\n",
        "      scroll_pause_time = 2 # Adjust if necessary\n",
        "      last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "      while True:\n",
        "            # Scroll down to the bottom of the page\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    \n",
        "            # Wait for the new page to load\n",
        "            time.sleep(scroll_pause_time)\n",
        "    \n",
        "            # Calculate new scroll height and compare with the last scroll height\n",
        "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "            if new_height == last_height:\n",
        "                  time.sleep(scroll_pause_time) # Wait for the potentially new content to load\n",
        "                  new_height = driver.execute_script(\"return document.body.scrollHeight\") # Try scroling once more\n",
        "                  if new_height == last_height:\n",
        "                        break  # Stop if we've reached the end of the page\n",
        "            last_height = new_height\n",
        "\n",
        "      # Get the final page source after all content is loaded\n",
        "      page_source = driver.page_source\n",
        "\n",
        "      # Parse the page source with BeautifulSoup\n",
        "      soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "      # Create empty lists to store the data\n",
        "      hyperlink = []\n",
        "      brands = []\n",
        "      wines = []\n",
        "      ratings = []\n",
        "      reviews = []\n",
        "      prices = []\n",
        "      timestamp = []\n",
        "\n",
        "      # Find all wine entries on the page\n",
        "      wine_entries = soup.find_all(class_='card__card--2R5Wh wineCard__wineCardContent--3cwZt')\n",
        "\n",
        "      for entry in wine_entries:\n",
        "\n",
        "            # Extract hyperlink\n",
        "            link_tag = entry.find('a', class_='wineCard__cardLink--3F_uB')\n",
        "            if link_tag and link_tag.has_attr('href'):\n",
        "                  hyperlink.append(link_tag['href'])\n",
        "\n",
        "            # Extract brand\n",
        "            brand = entry.find(class_='wineInfoVintage__truncate--3QAtw')\n",
        "            if brand:\n",
        "                  brands.append(brand.get_text(strip=True))\n",
        "\n",
        "            # Extract wine name\n",
        "            wine = entry.find(class_='wineInfoVintage__vintage--VvWlU wineInfoVintage__truncate--3QAtw') \n",
        "            if wine:\n",
        "                  wines.append(wine.get_text(strip=True))\n",
        "\n",
        "            # Extract rating\n",
        "            rating = entry.find(class_='vivinoRating_averageValue__uDdPM')\n",
        "            if rating:\n",
        "                  ratings.append(rating.get_text(strip=True))\n",
        "            # Extract review count\n",
        "            review = entry.find(class_='vivinoRating_caption__xL84P')\n",
        "            if review:\n",
        "                  # Get only the first part so the word 'beoordelingen' is not scraped\n",
        "                  review_text = review.get_text(strip=True)\n",
        "                  review_count = review_text.split()[0]\n",
        "                  reviews.append(review_count)\n",
        "            \n",
        "            # Check for the presence of the discount first\n",
        "            discount_price_div = entry.find(class_='price_strike__mOVjZ addToCart__subText--1pvFt')\n",
        "            if discount_price_div:\n",
        "                  # If discount exist, get the original price\n",
        "                  discount_price_text = discount_price_div.get_text(strip=True)\n",
        "                  price_only = discount_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "                  prices.append(price_only)  # Append only the discount price to the list\n",
        "    \n",
        "            else:  \n",
        "                  # Extract currency & price if present in the addToCartButton\n",
        "                  price_divs = entry.find_all(class_='addToCartButton__price--qJdh4')\n",
        "                  if price_divs:  # If primary price class exists\n",
        "                        for price_div in price_divs:\n",
        "                              currency = price_div.find('div', class_='addToCartButton__currency--2CTNX')\n",
        "                              price = price_div.find_all('div')[1]  # Assuming price is in the second div\n",
        "                              full_price = f\"{currency.get_text(strip=True) if currency else ''}{price.get_text(strip=True) if price else ''}\"\n",
        "                              prices.append(full_price)  # Save the full price\n",
        "                  else:  # If not present, extract price from alternative class (online verkrijgbaar vanaf...)\n",
        "                        alt_price_div = entry.find(class_='addToCart__subText--1pvFt addToCart__ppcPrice--ydrd5')\n",
        "                        if alt_price_div:\n",
        "                              alt_price_text = alt_price_div.get_text(strip=True)\n",
        "                              price_only = alt_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "                              prices.append(price_only)  # Append only the price to the list\n",
        "            \n",
        "            # Extract timestamp\n",
        "            timestamps = time.time()\n",
        "            timestamp.append(timestamps)\n",
        "\n",
        "            # Wait for 2 seconds to not overload the server\n",
        "            time.sleep(2)\n",
        "\n",
        "      # Open a csv file to store the data in\n",
        "      with open('red_wine.csv', mode='a', newline='', encoding='utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "\n",
        "            # Write the data rows\n",
        "            for hyperlink,brand, wine, rating, reviews, price, timestamp in zip(hyperlink,brands, wines, ratings, reviews, prices, timestamp):\n",
        "                  writer.writerow([\n",
        "                        hyperlink,\n",
        "                        brand,\n",
        "                        wine,\n",
        "                        rating,\n",
        "                        reviews,\n",
        "                        price,\n",
        "                        timestamp \n",
        "                  ])\n",
        "      \n",
        "      print(\"Data saved to 'red_wine.csv' successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## White Wines\n",
        "\n",
        "In the cell below we are collecting the data of the white wines. To be safe that the code doesn't break, we seperate the wines we want to extract into 2 seperate urls. These urls are then, one by one, fed into the code using a for loop. After scraping, the data will be appended to a csv file names 'white_wine.csv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTEMkIL-ymZW",
        "outputId": "6ca6a896-c27e-455a-f109-85dda755bc68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cookies accepted.\n",
            "Data saved to 'white_wine.csv' successfully.\n",
            "Cookie acceptance button not found or could not be clicked: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"didomi-notice-agree-button\"]\"}\n",
            "  (Session info: chrome=129.0.6668.70); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00717143+25587]\n",
            "\t(No symbol) [0x006AA2E4]\n",
            "\t(No symbol) [0x005A2113]\n",
            "\t(No symbol) [0x005E6F62]\n",
            "\t(No symbol) [0x005E71AB]\n",
            "\t(No symbol) [0x00627852]\n",
            "\t(No symbol) [0x0060ABE4]\n",
            "\t(No symbol) [0x00625370]\n",
            "\t(No symbol) [0x0060A936]\n",
            "\t(No symbol) [0x005DBA73]\n",
            "\t(No symbol) [0x005DC4CD]\n",
            "\tGetHandleVerifier [0x009F4C63+3030803]\n",
            "\tGetHandleVerifier [0x00A46B99+3366473]\n",
            "\tGetHandleVerifier [0x007A95F2+624802]\n",
            "\tGetHandleVerifier [0x007B0E6C+655644]\n",
            "\t(No symbol) [0x006B2C9D]\n",
            "\t(No symbol) [0x006AFD68]\n",
            "\t(No symbol) [0x006AFF05]\n",
            "\t(No symbol) [0x006A2336]\n",
            "\tBaseThreadInitThunk [0x75067BA9+25]\n",
            "\tRtlInitializeExceptionChain [0x7701C0CB+107]\n",
            "\tRtlClearBits [0x7701C04F+191]\n",
            "\n",
            "Data saved to 'white_wine.csv' successfully.\n"
          ]
        }
      ],
      "source": [
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service)\n",
        "\n",
        "urls = ('https://www.vivino.com/explore?e=eJzLLbI1VMvNzLM1UMtNrLA1MlBLrrT181FLtnUNDVIrAEqmp9mWJRZlppYk5qjlF6XYJhYnq-UnVdoWFGUmp6qVl0TH2hoBNRUD6dRiNTAJAJlRHFM%3D', # 0-20 euro\n",
        "        'https://www.vivino.com/explore?e=eJzLLbI1VMvNzLM1MlDLTaywNTUwUEuutPXzUUu2dQ0NUisASqen2ZYlFmWmliTmqOUXpdgmFier5SdV2hYUZSanqpWXRMfaGgE1FQPp1GI1MAkAvnccuA%3D%3D') # 20-500 euro\n",
        "\n",
        "# Open a csv file to store the data in\n",
        "with open('white_wine.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writerow(['hyperlink','Brand', 'Wine', 'Rating', 'Reviews', 'Price','Timestamp'])\n",
        "\n",
        "for url in urls:\n",
        "    driver.get(url)\n",
        "    driver.maximize_window()\n",
        "\n",
        "    # Optional: Adding some wait time for the page to fully load if needed\n",
        "    driver.implicitly_wait(20)\n",
        "\n",
        "    # Create a function to click away the cookies\n",
        "    try:\n",
        "        accept_cookies_button = driver.find_element(By.ID,\"didomi-notice-agree-button\")\n",
        "        accept_cookies_button.click()\n",
        "        print(\"Cookies accepted.\")\n",
        "    except Exception as e:\n",
        "        print(\"Cookie acceptance button not found or could not be clicked:\")\n",
        "\n",
        "    # Infinite scroll to load more content\n",
        "    scroll_pause_time = 2 # Adjust if necessary\n",
        "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "    while True:\n",
        "        # Scroll down to the bottom of the page\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    \n",
        "        # Wait for the new page to load\n",
        "        time.sleep(scroll_pause_time)\n",
        "    \n",
        "        # Calculate new scroll height and compare with the last scroll height\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            time.sleep(scroll_pause_time) # Wait for the potentially new content to load\n",
        "            new_height = driver.execute_script(\"return document.body.scrollHeight\") # Try scroling once more\n",
        "            if new_height == last_height:\n",
        "                break  # Stop if we've reached the end of the page\n",
        "        last_height = new_height\n",
        "\n",
        "    # Get the final page source after all content is loaded\n",
        "    page_source = driver.page_source\n",
        "\n",
        "    # Parse the page source with BeautifulSoup\n",
        "    soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "    # Create empty lists to store the data\n",
        "    hyperlink = []\n",
        "    brands = []\n",
        "    wines = []\n",
        "    ratings = []\n",
        "    reviews = []\n",
        "    prices = []\n",
        "    timestamp = []\n",
        "\n",
        "    # Find all wine entries on the page\n",
        "    wine_entries = soup.find_all(class_='card__card--2R5Wh wineCard__wineCardContent--3cwZt')\n",
        "\n",
        "    for entry in wine_entries:\n",
        "\n",
        "        # Extract hyperlink\n",
        "        link_tag = entry.find('a', class_='wineCard__cardLink--3F_uB')\n",
        "        if link_tag and link_tag.has_attr('href'):\n",
        "            hyperlink.append(link_tag['href'])\n",
        "\n",
        "        # Extract brand\n",
        "        brand = entry.find(class_='wineInfoVintage__truncate--3QAtw')\n",
        "        if brand:\n",
        "            brands.append(brand.get_text(strip=True))\n",
        "\n",
        "        # Extract wine name\n",
        "        wine = entry.find(class_='wineInfoVintage__vintage--VvWlU wineInfoVintage__truncate--3QAtw') \n",
        "        if wine:\n",
        "            wines.append(wine.get_text(strip=True))\n",
        "\n",
        "        # Extract rating\n",
        "        rating = entry.find(class_='vivinoRating_averageValue__uDdPM')\n",
        "        if rating:\n",
        "            ratings.append(rating.get_text(strip=True))\n",
        "        # Extract review count\n",
        "        review = entry.find(class_='vivinoRating_caption__xL84P')\n",
        "        if review:\n",
        "            # Get only the first part so the word 'beoordelingen' is not scraped\n",
        "            review_text = review.get_text(strip=True)\n",
        "            review_count = review_text.split()[0]\n",
        "            reviews.append(review_count)\n",
        "            \n",
        "        # Check for the presence of the discount first\n",
        "        discount_price_div = entry.find(class_='price_strike__mOVjZ addToCart__subText--1pvFt')\n",
        "        if discount_price_div:\n",
        "            # If discount exist, get the original price\n",
        "            discount_price_text = discount_price_div.get_text(strip=True)\n",
        "            price_only = discount_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "            prices.append(price_only)  # Append only the discount price to the list\n",
        "    \n",
        "        else:  \n",
        "            # Extract currency & price if present in the addToCartButton\n",
        "            price_divs = entry.find_all(class_='addToCartButton__price--qJdh4')\n",
        "            if price_divs:  # If primary price class exists\n",
        "                for price_div in price_divs:\n",
        "                    currency = price_div.find('div', class_='addToCartButton__currency--2CTNX')\n",
        "                    price = price_div.find_all('div')[1]  # Assuming price is in the second div\n",
        "                    full_price = f\"{currency.get_text(strip=True) if currency else ''}{price.get_text(strip=True) if price else ''}\"\n",
        "                    prices.append(full_price)  # Save the full price\n",
        "            else:  # If not present, extract price from alternative class (online verkrijgbaar vanaf...)\n",
        "                alt_price_div = entry.find(class_='addToCart__subText--1pvFt addToCart__ppcPrice--ydrd5')\n",
        "                if alt_price_div:\n",
        "                    alt_price_text = alt_price_div.get_text(strip=True)\n",
        "                    price_only = alt_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "                    prices.append(price_only)  # Append only the price to the list\n",
        "            \n",
        "        # Extract timestamp\n",
        "        timestamps = time.time()\n",
        "        timestamp.append(timestamps)\n",
        "\n",
        "        # Wait for 2 seconds to not overload the server\n",
        "        time.sleep(2)\n",
        "\n",
        "    # Open a csv file to store the data in\n",
        "    with open('white_wine.csv', mode='a', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the data rows\n",
        "        for hyperlink,brand, wine, rating, reviews, price, timestamp in zip(hyperlink,brands, wines, ratings, reviews, prices, timestamp):\n",
        "            writer.writerow([\n",
        "                hyperlink,\n",
        "                brand,\n",
        "                wine,\n",
        "                rating,\n",
        "                reviews,\n",
        "                price,\n",
        "                timestamp \n",
        "            ])\n",
        "      \n",
        "    print(\"Data saved to 'white_wine.csv' successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rose Wines\n",
        "\n",
        "In the cell below we are collecting the data of the red wines. Since the number of rose wines is not extensive, it is not necesarry to seperate the wines into seperate urls. Therefore, the code is only run once with the full set of rose wines. After scraping, the data will be appended to a csv file names 'rose_wine.csv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RadMpxRG1JFH",
        "outputId": "2ccca26b-1fab-4823-a0a4-4d2396e5876d"
      },
      "outputs": [
        {
          "ename": "NoSuchWindowException",
          "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=129.0.6668.70)\nStacktrace:\n\tGetHandleVerifier [0x00717143+25587]\n\t(No symbol) [0x006AA2E4]\n\t(No symbol) [0x005A2113]\n\t(No symbol) [0x0057E23B]\n\t(No symbol) [0x0061179F]\n\t(No symbol) [0x00624CB9]\n\t(No symbol) [0x0060A936]\n\t(No symbol) [0x005DBA73]\n\t(No symbol) [0x005DC4CD]\n\tGetHandleVerifier [0x009F4C63+3030803]\n\tGetHandleVerifier [0x00A46B99+3366473]\n\tGetHandleVerifier [0x007A95F2+624802]\n\tGetHandleVerifier [0x007B0E6C+655644]\n\t(No symbol) [0x006B2C9D]\n\t(No symbol) [0x006AFD68]\n\t(No symbol) [0x006AFF05]\n\t(No symbol) [0x006A2336]\n\tBaseThreadInitThunk [0x75067BA9+25]\n\tRtlInitializeExceptionChain [0x7701C0CB+107]\n\tRtlClearBits [0x7701C04F+191]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22256/2849259980.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.vivino.com/explore?e=eJwdi70KgCAABt_mmw1q_Ma2aAiaIsLMQkgNtb-3T1ruhuNsYAFrHAWsfFgJAfWybaBY9x2OXLeVlwxGJ7nDh4WLjgp-fhlkMm6Lk_KnS7jTMLLMd8zWET8_0d4gXQ%3D%3D'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Optional: Adding some wait time for the page to fully load if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\31637\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mmaximize_window\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;34m\"\"\"Maximizes the current window that webdriver is using.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW3C_MAXIMIZE_WINDOW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfullscreen_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\31637\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\31637\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=129.0.6668.70)\nStacktrace:\n\tGetHandleVerifier [0x00717143+25587]\n\t(No symbol) [0x006AA2E4]\n\t(No symbol) [0x005A2113]\n\t(No symbol) [0x0057E23B]\n\t(No symbol) [0x0061179F]\n\t(No symbol) [0x00624CB9]\n\t(No symbol) [0x0060A936]\n\t(No symbol) [0x005DBA73]\n\t(No symbol) [0x005DC4CD]\n\tGetHandleVerifier [0x009F4C63+3030803]\n\tGetHandleVerifier [0x00A46B99+3366473]\n\tGetHandleVerifier [0x007A95F2+624802]\n\tGetHandleVerifier [0x007B0E6C+655644]\n\t(No symbol) [0x006B2C9D]\n\t(No symbol) [0x006AFD68]\n\t(No symbol) [0x006AFF05]\n\t(No symbol) [0x006A2336]\n\tBaseThreadInitThunk [0x75067BA9+25]\n\tRtlInitializeExceptionChain [0x7701C0CB+107]\n\tRtlClearBits [0x7701C04F+191]\n"
          ]
        }
      ],
      "source": [
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service)\n",
        "\n",
        "# Opening the 'Vivino' website\n",
        "url = 'https://www.vivino.com/explore?e=eJwdi70KgCAABt_mmw1q_Ma2aAiaIsLMQkgNtb-3T1ruhuNsYAFrHAWsfFgJAfWybaBY9x2OXLeVlwxGJ7nDh4WLjgp-fhlkMm6Lk_KnS7jTMLLMd8zWET8_0d4gXQ%3D%3D'\n",
        "driver.get(url)\n",
        "driver.maximize_window()\n",
        "\n",
        "# Optional: Adding some wait time for the page to fully load if needed\n",
        "driver.implicitly_wait(20)  # 20 seconds \n",
        "\n",
        " # Create a function to click away the cookies\n",
        "try:\n",
        "    accept_cookies_button = driver.find_element(By.ID,\"didomi-notice-agree-button\")\n",
        "    accept_cookies_button.click()\n",
        "    print(\"Cookies accepted.\")\n",
        "except Exception as e:\n",
        "    print(\"Cookie acceptance button not found or could not be clicked:\")\n",
        "\n",
        "# Infinite scroll to load more content\n",
        "scroll_pause_time = 2  # Adjust if necessary\n",
        "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "while True:\n",
        "    # Scroll down to the bottom of the page\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    \n",
        "    # Wait for the new page to load\n",
        "    time.sleep(scroll_pause_time)\n",
        "    \n",
        "    # Calculate new scroll height and compare with the last scroll height\n",
        "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    if new_height == last_height:\n",
        "        time.sleep(scroll_pause_time)  # Wait for the potentially new content to load\n",
        "        break  # Stop if we've reached the end of the page\n",
        "    last_height = new_height\n",
        "\n",
        "# Get the final page source after all content is loaded\n",
        "page_source = driver.page_source\n",
        "\n",
        "# Parse the page source with BeautifulSoup\n",
        "soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "# Create empty lists to store the data\n",
        "hyperlink = []\n",
        "brands = []\n",
        "wines = []\n",
        "ratings = []\n",
        "reviews = []\n",
        "prices = []\n",
        "timestamp = []\n",
        "\n",
        "# Find all wine entries on the page\n",
        "wine_entries = soup.find_all(class_='card__card--2R5Wh wineCard__wineCardContent--3cwZt')\n",
        "\n",
        "for entry in wine_entries:\n",
        "\n",
        "    link_tag = entry.find('a', class_='wineCard__cardLink--3F_uB')\n",
        "    if link_tag and link_tag.has_attr('href'):\n",
        "        hyperlink.append(link_tag['href'])\n",
        "\n",
        "    # Extract brand\n",
        "    brand = entry.find(class_='wineInfoVintage__truncate--3QAtw')\n",
        "    if brand:\n",
        "        brands.append(brand.get_text(strip=True))\n",
        "\n",
        "    # Extract wine name\n",
        "    wine = entry.find(class_='wineInfoVintage__vintage--VvWlU wineInfoVintage__truncate--3QAtw') \n",
        "    if wine:\n",
        "        wines.append(wine.get_text(strip=True))\n",
        "\n",
        "    # Extract rating\n",
        "    rating = entry.find(class_='vivinoRating_averageValue__uDdPM')\n",
        "    if rating:\n",
        "        ratings.append(rating.get_text(strip=True))\n",
        "    \n",
        "    # Extract review count\n",
        "    review = entry.find(class_='vivinoRating_caption__xL84P')\n",
        "    if review:\n",
        "       # Get only the first part so the word 'beoordelingen' is not scraped\n",
        "        review_text = review.get_text(strip=True)\n",
        "        review_count = review_text.split()[0]\n",
        "        reviews.append(review_count)\n",
        "\n",
        "    # Check for the presence of the discount first\n",
        "    discount_price_div = entry.find(class_='price_strike__mOVjZ addToCart__subText--1pvFt')\n",
        "    if discount_price_div:\n",
        "        # If discount exist, get the original price\n",
        "        discount_price_text = discount_price_div.get_text(strip=True)\n",
        "        price_only = discount_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "        prices.append(price_only)  # Append only the discount price to the list\n",
        "    \n",
        "    else:  \n",
        "        # Extract currency & price if present in the addToCartButton\n",
        "        price_divs = entry.find_all(class_='addToCartButton__price--qJdh4')\n",
        "        if price_divs:  # If primary price class exists\n",
        "            for price_div in price_divs:\n",
        "                currency = price_div.find('div', class_='addToCartButton__currency--2CTNX')\n",
        "                price = price_div.find_all('div')[1]  # Assuming price is in the second div\n",
        "                full_price = f\"{currency.get_text(strip=True) if currency else ''}{price.get_text(strip=True) if price else ''}\"\n",
        "                prices.append(full_price)  # Save the full price\n",
        "        else:  # If not present, extract price from alternative class (online verkrijgbaar vanaf...)\n",
        "            alt_price_div = entry.find(class_='addToCart__subText--1pvFt addToCart__ppcPrice--ydrd5')\n",
        "            if alt_price_div:\n",
        "                alt_price_text = alt_price_div.get_text(strip=True)\n",
        "                price_only = alt_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "                prices.append(price_only)  # Append only the price to the list\n",
        "                \n",
        "    timestamps = time.time()\n",
        "    timestamp.append(timestamps)\n",
        "\n",
        "    # Wait for 2 seconds to not overload the server\n",
        "    time.sleep(2)\n",
        "\n",
        "# Open csv file to store the data\n",
        "with open('rose_wine.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writerow(['hyperlink','Brand', 'Wine', 'Rating', 'Reviews', 'Price','Timestamp'])\n",
        "\n",
        "    # Write the data rows\n",
        "    for hyperlink,brand, wine, rating, reviews, price, timestamp in zip(hyperlink, brands, wines, ratings, reviews, prices, timestamp):\n",
        "        writer.writerow([\n",
        "            hyperlink,\n",
        "            brand,\n",
        "            wine,\n",
        "            rating,\n",
        "            reviews,\n",
        "            price,\n",
        "            timestamp\n",
        "        ])\n",
        "\n",
        "print(\"Data saved to 'rose_wine.csv' successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sparkling Wines\n",
        "\n",
        "In the cell below we are collecting the data of the red wines. Since the number of sparkling wines is not extensive, it is not necesarry to seperate the wines into seperate urls. Therefore, the code is only run once with the full set of sparkling wines. After scraping, the data will be appended to a csv file names 'sparkling_wine.csv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UINhqcAS1xOF",
        "outputId": "4faa9a9e-cf58-4f06-9c22-782b953c848b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cookie acceptance button not found or could not be clicked: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"didomi-notice-agree-button\"]\"}\n",
            "  (Session info: chrome=129.0.6668.70); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "\tGetHandleVerifier [0x00717143+25587]\n",
            "\t(No symbol) [0x006AA2E4]\n",
            "\t(No symbol) [0x005A2113]\n",
            "\t(No symbol) [0x005E6F62]\n",
            "\t(No symbol) [0x005E71AB]\n",
            "\t(No symbol) [0x00627852]\n",
            "\t(No symbol) [0x0060ABE4]\n",
            "\t(No symbol) [0x00625370]\n",
            "\t(No symbol) [0x0060A936]\n",
            "\t(No symbol) [0x005DBA73]\n",
            "\t(No symbol) [0x005DC4CD]\n",
            "\tGetHandleVerifier [0x009F4C63+3030803]\n",
            "\tGetHandleVerifier [0x00A46B99+3366473]\n",
            "\tGetHandleVerifier [0x007A95F2+624802]\n",
            "\tGetHandleVerifier [0x007B0E6C+655644]\n",
            "\t(No symbol) [0x006B2C9D]\n",
            "\t(No symbol) [0x006AFD68]\n",
            "\t(No symbol) [0x006AFF05]\n",
            "\t(No symbol) [0x006A2336]\n",
            "\tBaseThreadInitThunk [0x75067BA9+25]\n",
            "\tRtlInitializeExceptionChain [0x7701C0CB+107]\n",
            "\tRtlClearBits [0x7701C04F+191]\n",
            "\n",
            "Data saved to 'sparkling_wine.csv' successfully.\n"
          ]
        }
      ],
      "source": [
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service)\n",
        "\n",
        "# Opening the 'Vivino' website\n",
        "url = 'https://www.vivino.com/explore?e=eJwdi70KgCAABt_mm41o_Ma2aAiaIsLMQkgNtb-3T1ruhuNsYAFrHAWsfFgJAfWybaBY9x2OXLeVlwxGJ7nDh4WLjgp-fhlkMm6Lk_KnS7jTMLLMd8zWET8_0c4gXA%3D%3D'\n",
        "driver.get(url)\n",
        "driver.maximize_window()\n",
        "\n",
        "# Optional: Adding some wait time for the page to fully load if needed\n",
        "driver.implicitly_wait(20)  # 20 seconds \n",
        "\n",
        " # Create a function to click away the cookies\n",
        "try:\n",
        "    accept_cookies_button = driver.find_element(By.ID,\"didomi-notice-agree-button\")\n",
        "    accept_cookies_button.click()\n",
        "    print(\"Cookies accepted.\")\n",
        "except Exception as e:\n",
        "    print(\"Cookie acceptance button not found or could not be clicked:\")\n",
        "\n",
        "# Infinite scroll to load more content\n",
        "scroll_pause_time = 2  # Adjust if necessary\n",
        "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "while True:\n",
        "    # Scroll down to the bottom of the page\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    \n",
        "    # Wait for the new page to load\n",
        "    time.sleep(scroll_pause_time)\n",
        "    \n",
        "    # Calculate new scroll height and compare with the last scroll height\n",
        "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    if new_height == last_height:\n",
        "        time.sleep(scroll_pause_time)  # Wait for the potentially new content to load\n",
        "        break  # Stop if we've reached the end of the page\n",
        "    last_height = new_height\n",
        "\n",
        "# Get the final page source after all content is loaded\n",
        "page_source = driver.page_source\n",
        "\n",
        "# Parse the page source with BeautifulSoup\n",
        "soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "# Create empty lists to store the data\n",
        "hyperlink = []\n",
        "brands = []\n",
        "wines = []\n",
        "ratings = []\n",
        "reviews = []\n",
        "prices = []\n",
        "timestamp = []\n",
        "\n",
        "# Find all wine entries on the page\n",
        "wine_entries = soup.find_all(class_='card__card--2R5Wh wineCard__wineCardContent--3cwZt')\n",
        "\n",
        "for entry in wine_entries:\n",
        "\n",
        "    link_tag = entry.find('a', class_='wineCard__cardLink--3F_uB')\n",
        "    if link_tag and link_tag.has_attr('href'):\n",
        "        hyperlink.append(link_tag['href'])\n",
        "\n",
        "    # Extract brand\n",
        "    brand = entry.find(class_='wineInfoVintage__truncate--3QAtw')\n",
        "    if brand:\n",
        "        brands.append(brand.get_text(strip=True))\n",
        "\n",
        "    # Extract wine name\n",
        "    wine = entry.find(class_='wineInfoVintage__vintage--VvWlU wineInfoVintage__truncate--3QAtw') \n",
        "    if wine:\n",
        "        wines.append(wine.get_text(strip=True))\n",
        "\n",
        "    # Extract rating\n",
        "    rating = entry.find(class_='vivinoRating_averageValue__uDdPM')\n",
        "    if rating:\n",
        "        ratings.append(rating.get_text(strip=True))\n",
        "    \n",
        "    # Extract review count\n",
        "    review = entry.find(class_='vivinoRating_caption__xL84P')\n",
        "    if review:\n",
        "       # Get only the first part so the word 'beoordelingen' is not scraped\n",
        "        review_text = review.get_text(strip=True)\n",
        "        review_count = review_text.split()[0]\n",
        "        reviews.append(review_count)\n",
        "\n",
        "    # Check for the presence of the discount first\n",
        "    discount_price_div = entry.find(class_='price_strike__mOVjZ addToCart__subText--1pvFt')\n",
        "    if discount_price_div:\n",
        "        # If discount exist, get the original price\n",
        "        discount_price_text = discount_price_div.get_text(strip=True)\n",
        "        price_only = discount_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "        prices.append(price_only)  # Append only the discount price to the list\n",
        "    \n",
        "    else:  \n",
        "        # Extract currency & price if present in the addToCartButton\n",
        "        price_divs = entry.find_all(class_='addToCartButton__price--qJdh4')\n",
        "        if price_divs:  # If primary price class exists\n",
        "            for price_div in price_divs:\n",
        "                currency = price_div.find('div', class_='addToCartButton__currency--2CTNX')\n",
        "                price = price_div.find_all('div')[1]  # Assuming price is in the second div\n",
        "                full_price = f\"{currency.get_text(strip=True) if currency else ''}{price.get_text(strip=True) if price else ''}\"\n",
        "                prices.append(full_price)  # Save the full price\n",
        "        else:  # If not present, extract price from alternative class (online verkrijgbaar vanaf...)\n",
        "            alt_price_div = entry.find(class_='addToCart__subText--1pvFt addToCart__ppcPrice--ydrd5')\n",
        "            if alt_price_div:\n",
        "                alt_price_text = alt_price_div.get_text(strip=True)\n",
        "                price_only = alt_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "                prices.append(price_only)  # Append only the price to the list\n",
        "                \n",
        "    timestamps = time.time()\n",
        "    timestamp.append(timestamps)\n",
        "\n",
        "    # Wait for 2 seconds to not overload the server\n",
        "    time.sleep(2)\n",
        "\n",
        "# Open csv file to store the data\n",
        "with open('sparkling_wine.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writerow(['hyperlink','Brand', 'Wine', 'Rating', 'Reviews', 'Price','Timestamp'])\n",
        "\n",
        "    # Write the data rows\n",
        "    for hyperlink,brand, wine, rating, reviews, price, timestamp in zip(hyperlink, brands, wines, ratings, reviews, prices, timestamp):\n",
        "        writer.writerow([\n",
        "            hyperlink,\n",
        "            brand,\n",
        "            wine,\n",
        "            rating,\n",
        "            reviews,\n",
        "            price,\n",
        "            timestamp\n",
        "        ])\n",
        "\n",
        "print(\"Data saved to 'sparkling_wine.csv' successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dessert Wines\n",
        "\n",
        "In the cell below we are collecting the data of the red wines. Since the number of dessert wines is not extensive, it is not necesarry to seperate the wines into seperate urls. Therefore, the code is only run once with the full set of dessert wines. After scraping, the data will be appended to a csv file names 'dessert_wine.csv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cookies accepted.\n",
            "Data saved to 'dessert_wine.csv' successfully.\n"
          ]
        }
      ],
      "source": [
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service)\n",
        "\n",
        "# Opening the 'Vivino' website\n",
        "url = 'https://www.vivino.com/explore?e=eJwdi70KgCAABt_mm22Ipm9si4agKSLMLITUUPt7-6TlbjjOBhawxlHAyoelEFAv2waKdd_hyHVbeclgdJI7fFi46Kjg55dBJuO2OCl_uoQ7DSOrfMdsHfHzA9IOIGA%3D'\n",
        "driver.get(url)\n",
        "driver.maximize_window()\n",
        "\n",
        "# Optional: Adding some wait time for the page to fully load if needed\n",
        "driver.implicitly_wait(20)  # 20 seconds \n",
        "\n",
        " # Create a function to click away the cookies\n",
        "try:\n",
        "    accept_cookies_button = driver.find_element(By.ID,\"didomi-notice-agree-button\")\n",
        "    accept_cookies_button.click()\n",
        "    print(\"Cookies accepted.\")\n",
        "except Exception as e:\n",
        "    print(\"Cookie acceptance button not found or could not be clicked:\")\n",
        "\n",
        "# Infinite scroll to load more content\n",
        "scroll_pause_time = 2  # Adjust if necessary\n",
        "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "while True:\n",
        "    # Scroll down to the bottom of the page\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    \n",
        "    # Wait for the new page to load\n",
        "    time.sleep(scroll_pause_time)\n",
        "    \n",
        "    # Calculate new scroll height and compare with the last scroll height\n",
        "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    if new_height == last_height:\n",
        "        time.sleep(scroll_pause_time)  # Wait for the potentially new content to load\n",
        "        break  # Stop if we've reached the end of the page\n",
        "    last_height = new_height\n",
        "\n",
        "# Get the final page source after all content is loaded\n",
        "page_source = driver.page_source\n",
        "\n",
        "# Parse the page source with BeautifulSoup\n",
        "soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "# Create empty lists to store the data\n",
        "hyperlink = []\n",
        "brands = []\n",
        "wines = []\n",
        "ratings = []\n",
        "reviews = []\n",
        "prices = []\n",
        "timestamp = []\n",
        "\n",
        "# Find all wine entries on the page\n",
        "wine_entries = soup.find_all(class_='card__card--2R5Wh wineCard__wineCardContent--3cwZt')\n",
        "\n",
        "for entry in wine_entries:\n",
        "\n",
        "    link_tag = entry.find('a', class_='wineCard__cardLink--3F_uB')\n",
        "    if link_tag and link_tag.has_attr('href'):\n",
        "        hyperlink.append(link_tag['href'])\n",
        "\n",
        "    # Extract brand\n",
        "    brand = entry.find(class_='wineInfoVintage__truncate--3QAtw')\n",
        "    if brand:\n",
        "        brands.append(brand.get_text(strip=True))\n",
        "\n",
        "    # Extract wine name\n",
        "    wine = entry.find(class_='wineInfoVintage__vintage--VvWlU wineInfoVintage__truncate--3QAtw') \n",
        "    if wine:\n",
        "        wines.append(wine.get_text(strip=True))\n",
        "\n",
        "    # Extract rating\n",
        "    rating = entry.find(class_='vivinoRating_averageValue__uDdPM')\n",
        "    if rating:\n",
        "        ratings.append(rating.get_text(strip=True))\n",
        "    \n",
        "    # Extract review count\n",
        "    review = entry.find(class_='vivinoRating_caption__xL84P')\n",
        "    if review:\n",
        "       # Get only the first part so the word 'beoordelingen' is not scraped\n",
        "        review_text = review.get_text(strip=True)\n",
        "        review_count = review_text.split()[0]\n",
        "        reviews.append(review_count)\n",
        "\n",
        "    # Check for the presence of the discount first\n",
        "    discount_price_div = entry.find(class_='price_strike__mOVjZ addToCart__subText--1pvFt')\n",
        "    if discount_price_div:\n",
        "        # If discount exist, get the original price\n",
        "        discount_price_text = discount_price_div.get_text(strip=True)\n",
        "        price_only = discount_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "        prices.append(price_only)  # Append only the discount price to the list\n",
        "    \n",
        "    else:  \n",
        "        # Extract currency & price if present in the addToCartButton\n",
        "        price_divs = entry.find_all(class_='addToCartButton__price--qJdh4')\n",
        "        if price_divs:  # If primary price class exists\n",
        "            for price_div in price_divs:\n",
        "                currency = price_div.find('div', class_='addToCartButton__currency--2CTNX')\n",
        "                price = price_div.find_all('div')[1]  # Assuming price is in the second div\n",
        "                full_price = f\"{currency.get_text(strip=True) if currency else ''}{price.get_text(strip=True) if price else ''}\"\n",
        "                prices.append(full_price)  # Save the full price\n",
        "        else:  # If not present, extract price from alternative class (online verkrijgbaar vanaf...)\n",
        "            alt_price_div = entry.find(class_='addToCart__subText--1pvFt addToCart__ppcPrice--ydrd5')\n",
        "            if alt_price_div:\n",
        "                alt_price_text = alt_price_div.get_text(strip=True)\n",
        "                price_only = alt_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "                prices.append(price_only)  # Append only the price to the list\n",
        "                \n",
        "    timestamps = time.time()\n",
        "    timestamp.append(timestamps)\n",
        "\n",
        "    # Wait for 2 seconds to not overload the server\n",
        "    time.sleep(2)\n",
        "\n",
        "# Open csv file to store the data\n",
        "with open('dessert_wine.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writerow(['hyperlink','Brand', 'Wine', 'Rating', 'Reviews', 'Price','Timestamp'])\n",
        "\n",
        "    # Write the data rows\n",
        "    for hyperlink,brand, wine, rating, reviews, price, timestamp in zip(hyperlink, brands, wines, ratings, reviews, prices, timestamp):\n",
        "        writer.writerow([\n",
        "            hyperlink,\n",
        "            brand,\n",
        "            wine,\n",
        "            rating,\n",
        "            reviews,\n",
        "            price,\n",
        "            timestamp\n",
        "        ])\n",
        "\n",
        "print(\"Data saved to 'dessert_wine.csv' successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fortified Wines\n",
        "\n",
        "In the cell below we are collecting the data of the red wines. Since the number of fortified wines is not extensive, it is not necesarry to seperate the wines into seperate urls. Therefore, the code is only run once with the full set of fortified wines. After scraping, the data will be appended to a csv file names 'fortified_wine.csv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cookies accepted.\n",
            "Data saved to 'fortified_wine.csv' successfully.\n"
          ]
        }
      ],
      "source": [
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service)\n",
        "\n",
        "# Opening the 'Vivino' website\n",
        "url = 'https://www.vivino.com/explore?e=eJzLLbI1VMvNzLM1UMtNrLA1NTBQS6609fNRS7Z1DQ1SKwDKpqfZliUWZaaWJOao5Rel2CYWJ6vlJ1XaFhRlJqeqlZdEx9oamQB1FQMZqcVqYBIAxtccug%3D%3D'\n",
        "driver.get(url)\n",
        "driver.maximize_window()\n",
        "\n",
        "# Optional: Adding some wait time for the page to fully load if needed\n",
        "driver.implicitly_wait(20)  # 20 seconds \n",
        "\n",
        " # Create a function to click away the cookies\n",
        "try:\n",
        "    accept_cookies_button = driver.find_element(By.ID,\"didomi-notice-agree-button\")\n",
        "    accept_cookies_button.click()\n",
        "    print(\"Cookies accepted.\")\n",
        "except Exception as e:\n",
        "    print(\"Cookie acceptance button not found or could not be clicked:\")\n",
        "\n",
        "# Infinite scroll to load more content\n",
        "scroll_pause_time = 2  # Adjust if necessary\n",
        "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "while True:\n",
        "    # Scroll down to the bottom of the page\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    \n",
        "    # Wait for the new page to load\n",
        "    time.sleep(scroll_pause_time)\n",
        "    \n",
        "    # Calculate new scroll height and compare with the last scroll height\n",
        "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    if new_height == last_height:\n",
        "        time.sleep(scroll_pause_time)  # Wait for the potentially new content to load\n",
        "        break  # Stop if we've reached the end of the page\n",
        "    last_height = new_height\n",
        "\n",
        "# Get the final page source after all content is loaded\n",
        "page_source = driver.page_source\n",
        "\n",
        "# Parse the page source with BeautifulSoup\n",
        "soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "# Create empty lists to store the data\n",
        "hyperlink = []\n",
        "brands = []\n",
        "wines = []\n",
        "ratings = []\n",
        "reviews = []\n",
        "prices = []\n",
        "timestamp = []\n",
        "\n",
        "# Find all wine entries on the page\n",
        "wine_entries = soup.find_all(class_='card__card--2R5Wh wineCard__wineCardContent--3cwZt')\n",
        "\n",
        "for entry in wine_entries:\n",
        "\n",
        "    link_tag = entry.find('a', class_='wineCard__cardLink--3F_uB')\n",
        "    if link_tag and link_tag.has_attr('href'):\n",
        "        hyperlink.append(link_tag['href'])\n",
        "\n",
        "    # Extract brand\n",
        "    brand = entry.find(class_='wineInfoVintage__truncate--3QAtw')\n",
        "    if brand:\n",
        "        brands.append(brand.get_text(strip=True))\n",
        "\n",
        "    # Extract wine name\n",
        "    wine = entry.find(class_='wineInfoVintage__vintage--VvWlU wineInfoVintage__truncate--3QAtw') \n",
        "    if wine:\n",
        "        wines.append(wine.get_text(strip=True))\n",
        "\n",
        "    # Extract rating\n",
        "    rating = entry.find(class_='vivinoRating_averageValue__uDdPM')\n",
        "    if rating:\n",
        "        ratings.append(rating.get_text(strip=True))\n",
        "    \n",
        "    # Extract review count\n",
        "    review = entry.find(class_='vivinoRating_caption__xL84P')\n",
        "    if review:\n",
        "       # Get only the first part so the word 'beoordelingen' is not scraped\n",
        "        review_text = review.get_text(strip=True)\n",
        "        review_count = review_text.split()[0]\n",
        "        reviews.append(review_count)\n",
        "\n",
        "    # Check for the presence of the discount first\n",
        "    discount_price_div = entry.find(class_='price_strike__mOVjZ addToCart__subText--1pvFt')\n",
        "    if discount_price_div:\n",
        "        # If discount exist, get the original price\n",
        "        discount_price_text = discount_price_div.get_text(strip=True)\n",
        "        price_only = discount_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "        prices.append(price_only)  # Append only the discount price to the list\n",
        "    \n",
        "    else:  \n",
        "        # Extract currency & price if present in the addToCartButton\n",
        "        price_divs = entry.find_all(class_='addToCartButton__price--qJdh4')\n",
        "        if price_divs:  # If primary price class exists\n",
        "            for price_div in price_divs:\n",
        "                currency = price_div.find('div', class_='addToCartButton__currency--2CTNX')\n",
        "                price = price_div.find_all('div')[1]  # Assuming price is in the second div\n",
        "                full_price = f\"{currency.get_text(strip=True) if currency else ''}{price.get_text(strip=True) if price else ''}\"\n",
        "                prices.append(full_price)  # Save the full price\n",
        "        else:  # If not present, extract price from alternative class (online verkrijgbaar vanaf...)\n",
        "            alt_price_div = entry.find(class_='addToCart__subText--1pvFt addToCart__ppcPrice--ydrd5')\n",
        "            if alt_price_div:\n",
        "                alt_price_text = alt_price_div.get_text(strip=True)\n",
        "                price_only = alt_price_text.split()[-1]  # Get the last part (currency + price)\n",
        "                prices.append(price_only)  # Append only the price to the list\n",
        "                \n",
        "    timestamps = time.time()\n",
        "    timestamp.append(timestamps)\n",
        "    \n",
        "    # Wait for 2 seconds to not overload the server\n",
        "    time.sleep(2)\n",
        "\n",
        "# Open csv file to store the data\n",
        "with open('fortified_wine.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writerow(['hyperlink','Brand', 'Wine', 'Rating', 'Reviews', 'Price','Timestamp'])\n",
        "\n",
        "    # Write the data rows\n",
        "    for hyperlink,brand, wine, rating, reviews, price, timestamp in zip(hyperlink, brands, wines, ratings, reviews, prices, timestamp):\n",
        "        writer.writerow([\n",
        "            hyperlink,\n",
        "            brand,\n",
        "            wine,\n",
        "            rating,\n",
        "            reviews,\n",
        "            price,\n",
        "            timestamp\n",
        "        ])\n",
        "\n",
        "print(\"Data saved to 'fortified_wine.csv' successfully.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
